{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 92) (train.py, line 92)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3553\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[1], line 17\u001b[0m\n    import utils_gan\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/tank/local/ndf3868/GODDS/GAN/utils_gan/__init__.py:12\u001b[0;36m\n\u001b[0;31m    from training.train import train\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/tank/local/ndf3868/GODDS/GAN/utils_gan/training/train.py:92\u001b[0;36m\u001b[0m\n\u001b[0;31m    pbar.set_description(f\"Epoch {epoch} Step {cur_step}:\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 92)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "import datetime\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath('/tank/local/ndf3868/GODDS/GAN'))\n",
    "\n",
    "# file_path = os.path.realpath(__file__)\n",
    "\n",
    "import utils_gan\n",
    "\n",
    "from utils_gan import ASV_DATASET, Generator, Discriminator, Whispers, \\\n",
    "    train, test_metrics, test_data, set_up_metrics_list, \\\n",
    "        visualize, visualize_separate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_timestamp():\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%d%m%y-%H:%M:%S\")\n",
    "    return timestamp\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "def get_balanced_indeces(dataset, n_samples_per_class, shuffle):\n",
    "    class_indeces = []\n",
    "\n",
    "    for label, indices in dataset.class_indeces.items():\n",
    "        class_indeces.extend(np.random.choice(indices, n_samples_per_class, replace=False))\n",
    "    \n",
    "    if shuffle: np.random.shuffle(class_indeces)\n",
    "    return class_indeces\n",
    "\n",
    "# set_seed(3407)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 3407\n"
     ]
    }
   ],
   "source": [
    "set_seed(3407)\n",
    "\n",
    "train_with_wisper   = True\n",
    "\n",
    "bonafide_class      = 0\n",
    "\n",
    "bootstrap_iterations= 1 #5\n",
    "n_epochs            = 1 #15\n",
    "\n",
    "input_size  = 190_000\n",
    "hidden_size = 200\n",
    "output_size = 1\n",
    "\n",
    "lr = 1e-8\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# audio_samples = torch.rand(size=(8, input_size), dtype=torch.float32) - 0.5\n",
    "# targets = torch.randint(low=0, high=2, size=(8, 1))\n",
    "\n",
    "# Generator & Optimizer for Generator\n",
    "gen = Generator(input_size, hidden_size).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "# Discriminator & Optimizer for Discriminator\n",
    "disc = Discriminator(input_size, hidden_size, output_size).to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "whisper_model_config_directory = '/tank/local/ndf3868/GODDS/GAN/whisper_config/finetuned_ITW'\n",
    "\n",
    "whisper_models_direstories = [\n",
    "    # models trained on Marco's test split (from pre-trained checkpoint)\n",
    "    '/tank/local/ndf3868/GODDS/GAN/whisper_config/finetuned_ITW/lfcc_lcnn_20240615_160043',\n",
    "    '/tank/local/ndf3868/GODDS/GAN/whisper_config/finetuned_ITW/rawnet3_20240615_224507',\n",
    "    # '/tank/local/ndf3868/GODDS/deepfake-whisper/src/models/whisper_lcnn/20240512_000000',\n",
    "    # '/tank/local/ndf3868/GODDS/deepfake-whisper/src/models/whisper_mesonet/20240512_000000',\n",
    "    # '/tank/local/ndf3868/GODDS/deepfake-whisper/src/models/whisper_mfcc_lcnn/20240516_005202',\n",
    "    # '/tank/local/ndf3868/GODDS/deepfake-whisper/src/models/whisper_mfcc_mesonet/20240513_131017',\n",
    "    # '/tank/local/ndf3868/GODDS/deepfake-whisper/src/models/whisper_mfcc_specrnet/20240516_030405',\n",
    "    # '/tank/local/ndf3868/GODDS/deepfake-whisper/src/models/whisper_specrnet/20240512_000000',\n",
    "]\n",
    "\n",
    "whisp     = Whispers(whisper_models_direstories, output_size, device).to(device) # for whisper bonafide class == 1\n",
    "whisp_opt = torch.optim.Adam(whisp.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading TRAIN dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading\n",
      "reading TEST  dataset\n",
      "Finished reading\n"
     ]
    }
   ],
   "source": [
    "asv_directory = '/tank/local/ndf3868/GODDS/datasets/ASV'\n",
    "print(\"reading TRAIN dataset\")\n",
    "train_dataset = ASV_DATASET(asv_directory, 'train', 'LA', class_balance=None, gen_fake=True) #oversample undersample undersample_all\n",
    "print(\"reading TEST  dataset\")\n",
    "test_dataset  = ASV_DATASET(asv_directory, 'dev',   'LA', class_balance=None, gen_fake=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling TEST dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"sampling TEST dataset\")\n",
    "sampler = SubsetRandomSampler(get_balanced_indeces(dataset=test_dataset, n_samples_per_class=450, shuffle=False))\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils_gan)\n",
    "\n",
    "from utils_gan import ASV_DATASET, Generator, Discriminator, Whispers, \\\n",
    "    train, test_metrics, test_data, set_up_metrics_list, \\\n",
    "        visualize, visualize_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling TRAIN dataset for bootstrap iteration 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bde5af63efe4670beedf9ed6ed4d9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "description:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'gen_loss' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, sampler\u001b[38;5;241m=\u001b[39msampler)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(get_current_timestamp())\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train(train_with_wisper, train_dataloader, train_dataset,\n\u001b[1;32m     11\u001b[0m     gen,      disc,     whisp,\n\u001b[1;32m     12\u001b[0m     gen_opt,  disc_opt, whisp_opt,\n\u001b[1;32m     13\u001b[0m     criterion,\n\u001b[1;32m     14\u001b[0m     n_epochs, device)\n\u001b[1;32m     16\u001b[0m logs_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tank/local/ndf3868/GODDS/GAN/logs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m full_real, full_noised, full_nonnoised \u001b[38;5;241m=\u001b[39m test_data(gen, disc, test_dataloader, device)\n",
      "File \u001b[0;32m/tank/local/ndf3868/GODDS/GAN/utils_gan/training/train.py:17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_with_wisper, dataloader, dataset, gen, disc, whisp, gen_opt, disc_opt, whisp_opt, criterion, n_epochs, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(train_with_wisper, dataloader, dataset,\n\u001b[1;32m     12\u001b[0m             gen,        disc,       whisp,\n\u001b[1;32m     13\u001b[0m             gen_opt,    disc_opt,   whisp_opt, \n\u001b[1;32m     14\u001b[0m             criterion,\n\u001b[1;32m     15\u001b[0m             n_epochs, device):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs): \u001b[38;5;66;03m#tqdm(range(n_epochs), desc='Training', leave):\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         train_epoch(train_with_wisper, dataloader, dataset,\n\u001b[1;32m     18\u001b[0m             gen,        disc,       whisp,\n\u001b[1;32m     19\u001b[0m             gen_opt,    disc_opt,   whisp_opt, \n\u001b[1;32m     20\u001b[0m             criterion,\n\u001b[1;32m     21\u001b[0m             epoch, device)\n",
      "File \u001b[0;32m/tank/local/ndf3868/GODDS/GAN/utils_gan/training/train.py:79\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_with_wisper, dataloader, dataset, gen, disc, whisp, gen_opt, disc_opt, whisp_opt, criterion, epoch, device)\u001b[0m\n\u001b[1;32m     75\u001b[0m         whisp_noised_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(whisp_noised_pred) \u001b[38;5;241m-\u001b[39m whisp_noised_pred\n\u001b[1;32m     78\u001b[0m mean_discriminator_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m disc_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m display_step\n\u001b[0;32m---> 79\u001b[0m mean_generator_loss     \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m  gen_loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m display_step\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_step \u001b[38;5;241m%\u001b[39m display_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cur_step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Generator loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_generator_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, discriminator loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_discriminator_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Last Beatch: Fake \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisc_fake_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m   Real\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisc_real_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'gen_loss' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "for _ in range(bootstrap_iterations):\n",
    "\n",
    "    print(\"sampling TRAIN dataset for bootstrap iteration\", _)\n",
    "    sampler = SubsetRandomSampler(get_balanced_indeces(dataset=train_dataset, n_samples_per_class=100, shuffle=True))\n",
    "    # dataset = CustomAudioDataset(audio_samples, targets)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=2, sampler=sampler)\n",
    "\n",
    "\n",
    "    # print(get_current_timestamp())\n",
    "    train(train_with_wisper, train_dataloader, train_dataset,\n",
    "        gen,      disc,     whisp,\n",
    "        gen_opt,  disc_opt, whisp_opt,\n",
    "        criterion,\n",
    "        n_epochs, device)\n",
    "    \n",
    "    logs_dir = '/tank/local/ndf3868/GODDS/GAN/logs'\n",
    "\n",
    "    full_real, full_noised, full_nonnoised = test_data(gen, disc, test_dataloader, device)\n",
    "\n",
    "    metrics_list = set_up_metrics_list(train_dataset.bonafide_class)\n",
    "    metrics      = test_metrics(metrics_list, full_real, full_noised, full_nonnoised)\n",
    "\n",
    "    visualize_separate(full_noised, full_nonnoised, os.path.join(logs_dir, f'density_distribution_{_}.png'))\n",
    "\n",
    "    timestamp = f'{get_current_timestamp()}'\n",
    "    timestamp = 'None'\n",
    "    with open(os.path.join(logs_dir, f\"{timestamp}_sample_iteration_{_}.json\"), \"w\") as outfile: \n",
    "        json.dump(metrics, outfile)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
